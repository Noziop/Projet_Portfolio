# app/tasks/download/workflow.py
import logging
from uuid import UUID

from celery import chain, chord

from app.db.session import SyncSessionLocal
from app.core.celery import celery_app
from app.infrastructure.repositories.task_repository import TaskRepository
from app.domain.value_objects.task_types import TaskStatus

from .search import search_observations
from .select import select_files
from .download import download_chunk
from .finalize import finalize_download

# Configuration du logging
workflow_logger = logging.getLogger('app.task.download.workflow')

@celery_app.task(name="app.tasks.download.workflow.create_download_tasks")
def create_download_tasks(selection_result):
    """Cr√©e des t√¢ches parall√®les pour chaque chunk de fichiers"""
    task_id = selection_result.get("task_id")
    
    if selection_result.get("status") != "success":
        error_msg = selection_result.get("message", "Erreur lors de la s√©lection des fichiers")
        workflow_logger.error(f"S√©lection √©chou√©e pour {task_id}: {error_msg}")
        return selection_result
    
    file_chunks = selection_result.get("file_chunks", [])
    
    if not file_chunks:
        workflow_logger.warning(f"Aucun chunk de fichiers √† t√©l√©charger pour {task_id}")
        return {
            "task_id": task_id,
            "status": "error",
            "message": "Aucun fichier √† t√©l√©charger"
        }
    
    workflow_logger.info(f"Cr√©ation de {len(file_chunks)} t√¢ches de t√©l√©chargement pour {task_id}")
    
    # Cr√©er des t√¢ches parall√®les pour chaque chunk
    parallel_tasks = []
    for i in range(len(file_chunks)):
        parallel_tasks.append(download_chunk.s(selection_result, i))
    
    # Utiliser chord pour ex√©cuter les t√©l√©chargements en parall√®le
    # puis finaliser une fois tous termin√©s
    chord_workflow = chord(parallel_tasks)(finalize_download.s())
    chord_workflow.apply_async()

    
    return {"status": "success", "message": f"T√©l√©chargement lanc√© avec {len(parallel_tasks)} t√¢ches parall√®les"}

@celery_app.task(name="app.tasks.download.workflow.start_mast_download")
def start_mast_download(task_id, target_id, telescope_id):
    """Point d'entr√©e principal pour le t√©l√©chargement MAST"""
    workflow_logger.info(f"D√©marrage du workflow de t√©l√©chargement: task_id={task_id}")
    
    # Mise √† jour initiale du statut
    with SyncSessionLocal() as session:
        task_repo = TaskRepository(session)
        task = task_repo.get_sync(UUID(task_id))
        
        if not task:
            workflow_logger.error(f"T√¢che {task_id} non trouv√©e")
            return {"status": "error", "message": f"T√¢che {task_id} non trouv√©e"}
        
        task.status = TaskStatus.RUNNING
        task.error = "D√©marrage du t√©l√©chargement"
        task_repo.update_sync(task)
        session.commit()
    
    # Construction et lancement du workflow
    workflow = chain(
        search_observations.s(task_id, target_id, telescope_id),
        select_files.s(),
        create_download_tasks.s()
    )
    
    workflow_logger.info(f"Lancement du workflow pour task_id={task_id}")
    workflow.apply_async()
    
    return {"status": "success", "message": "Workflow de t√©l√©chargement d√©marr√©"}

# Point d'entr√©e compatible avec l'existant
@celery_app.task(name="app.tasks.download.workflow.download_mast_files")
def download_mast_files(**kwargs):
    """Version ultra-simplifi√©e pour la d√©mo"""
    task_id = kwargs.get("task_id")
    target_id = kwargs.get("target_id")
    telescope_id = kwargs.get("telescope_id")
    preset_id = kwargs.get("preset_id")
    
    workflow_logger.info(f"üì• V√©rification/t√©l√©chargement pour: task_id={task_id}, target={target_id}")
    
    # V√©rification directe avec MinIO au lieu d'utiliser check_files_exist
    from app.services.storage.service import StorageService
    storage = StorageService()
    
    try:
        # Utiliser directement le client MinIO pour v√©rifier les fichiers
        objects = list(storage.client.list_objects(
            storage.fits_bucket,
            prefix=f"{target_id}/",
            recursive=True
        ))
        
        # Compter les fichiers FITS
        fits_files = [obj.object_name for obj in objects 
                     if obj.object_name.endswith('.fits') or obj.object_name.endswith('.fit')]
        
        # S'il y a des fichiers, on consid√®re que c'est bon
        if fits_files:
            nb_files = len(fits_files)
            message = f"{nb_files} fichiers disponibles"
            workflow_logger.info(f"‚úÖ {message}")
            
            # Mettre √† jour le statut
            from ..common import update_task_status_sync
            update_task_status_sync(task_id, TaskStatus.COMPLETED, message)
            
            return {"status": "success", "message": message}
        
        # Sinon lancer le workflow normal
        workflow_logger.info("‚ö†Ô∏è Aucun fichier existant, lancement du t√©l√©chargement complet")
        workflow = chain(
            search_observations.s(task_id, target_id, telescope_id),
            select_files.s(),
            create_download_tasks.s()
        )
        workflow.apply_async()
        return {"status": "success", "message": "Workflow de t√©l√©chargement d√©marr√©"}
    
    except Exception as e:
        workflow_logger.error(f"Erreur: {str(e)}")
        return {"status": "error", "message": str(e)}
